{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4RsRTYzXCm2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "from random import shuffle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "from torchsummary import summary\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from __future__ import print_function\n",
        "import itertools\n",
        "from torch.utils.data import Dataset , DataLoader\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNAjSbsUX-yq"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQ_v0MjHXCm7"
      },
      "outputs": [],
      "source": [
        " # Load  data \n",
        "\n",
        "# seed_indx=[1, 5, 9, 13]\n",
        "\n",
        "dir='/content/drive/MyDrive/sensor_data/'\n",
        "seed=5\n",
        "x_train = np.load(dir+'x_train_'+str(seed)+'.npy')\n",
        "y_train = np.load(dir+'y_train_'+str(seed)+'.npy')\n",
        "x_test = np.load(dir+'x_test_'+str(seed)+'.npy')\n",
        "y_test = np.load(dir+'y_test_'+str(seed)+'.npy')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "GBBfSphyMI0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6jiSNLOXCm8"
      },
      "outputs": [],
      "source": [
        "print(x_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuASdnErXCm8"
      },
      "outputs": [],
      "source": [
        "class SensorDataset(Dataset): \n",
        "\n",
        "    def __init__(self, x, y):        \n",
        "        self.n_samples = x.shape[0]\n",
        "        self.x_data = torch.from_numpy(x).float() \n",
        "        self.y_data = torch.from_numpy(y).float() \n",
        "        \n",
        "    # support indexing such that dataset[i] can be used to get i-th sample\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    # we can call len(dataset) to return the size\n",
        "    def __len__(self):\n",
        "        return self.n_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUFaca4VXCm9"
      },
      "outputs": [],
      "source": [
        "train_dataset = SensorDataset(x_train,y_train) \n",
        "test_dataset = SensorDataset(x_test,y_test) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29esi-BwXCm9"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "train_dataloader = DataLoader(train_dataset,batch_size,drop_last=True)\n",
        "test_dataloader = DataLoader(test_dataset,batch_size , drop_last=True)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fO4l6jCNXCm-"
      },
      "outputs": [],
      "source": [
        "class Lstm_model(nn.Module):\n",
        "    def __init__(self, input_dim , hidden_size , num_layers):\n",
        "        super(Lstm_model, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.input_size = input_dim\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = nn.LSTM(input_size=input_dim , hidden_size = hidden_size , num_layers= num_layers )\n",
        "        self.fc = nn.Linear(hidden_size,1)\n",
        "\n",
        "    def forward(self,x,hn,cn):\n",
        "        out , (hn,cn) = self.lstm(x , (hn,cn))\n",
        "        final_out = self.fc(out[-1])\n",
        "        return final_out,hn,cn\n",
        "\n",
        "    def predict(self,x):\n",
        "        hn,cn  = self.init()\n",
        "        final_out = self.fc(out[-1])\n",
        "        return final_out\n",
        "\n",
        "    def init(self):\n",
        "        h0 =  torch.zeros(self.num_layers , batch_size , self.hidden_size).to(device)\n",
        "        c0 =  torch.zeros(self.num_layers , batch_size , self.hidden_size).to(device)\n",
        "        return h0 , c0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZa7vM1EXCm_"
      },
      "outputs": [],
      "source": [
        "input_dim = 1 \n",
        "hidden_size = 50\n",
        "num_layers = 4\n",
        "\n",
        "model = Lstm_model(input_dim , hidden_size , num_layers).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ja7PwLPHXCm_"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k20ucPTRXCnA"
      },
      "outputs": [],
      "source": [
        "def train(dataloader):\n",
        "    hn , cn = model.init()\n",
        "    model.train()\n",
        "    for batch , item in enumerate(dataloader):\n",
        "        x , y = item\n",
        "        y=torch.squeeze(y)\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        # out , hn , cn = model(torch.unsqueeze(torch.t(x), 2),hn,cn) #pytorch compatible reshaping [time seq, batch, n_feat]\n",
        "        out , hn , cn = model(x.reshape(48,batch_size,1),hn,cn)\n",
        "\n",
        "        loss = loss_fn(out.reshape(batch_size), y)\n",
        "        hn = hn.detach()\n",
        "        cn = cn.detach()\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if batch == len(dataloader)-1:\n",
        "            loss = loss.item()\n",
        "            print(f\"train loss: {loss:>7f} \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRw-7zUUXCnA"
      },
      "outputs": [],
      "source": [
        "def test(dataloader):\n",
        "    hn , cn = model.init()\n",
        "    model.eval()\n",
        "    for batch , item in enumerate(dataloader):\n",
        "        x , y = item\n",
        "        y=torch.squeeze(y)\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        out , hn , cn = model(x.reshape(48,batch_size,1),hn,cn)\n",
        "        # out , hn , cn = model(torch.unsqueeze(torch.t(x), 2),hn,cn)\n",
        "        loss = loss_fn(out.reshape(batch_size) , y)\n",
        "       \n",
        "        if batch == len(dataloader)-1:\n",
        "            loss = loss.item()\n",
        "            print(f\"test loss: {loss:>7f} \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvAcwZcLXCnB"
      },
      "outputs": [],
      "source": [
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    print(f\"epoch {epoch} \")\n",
        "    train(train_dataloader)\n",
        "    test(test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7QAVitHpjWP"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "def calculate_metrics(data_loader):\n",
        "    pred_arr = []\n",
        "    y_arr = []\n",
        "    with torch.no_grad():\n",
        "        hn , cn = model.init()\n",
        "        for batch , item in enumerate(data_loader):\n",
        "            x , y = item\n",
        "            x , y = x.to(device) , y.to(device)\n",
        "            x = x.view(48,64,1)\n",
        "            pred = model(x,hn,cn)[0]\n",
        "            pred=pred.cpu().detach().numpy()\n",
        "            y=y.cpu().detach().numpy()\n",
        "            pred_arr = pred_arr + list(pred)\n",
        "            y_arr = y_arr + list(y)\n",
        "            # print(pred_arr,y_arr[21])\n",
        "        \n",
        "        print(pred_arr[21],y_arr[21])\n",
        "        return y_arr, pred_arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfDxHXcn2SQP"
      },
      "outputs": [],
      "source": [
        "y_arr, pred_arr=calculate_metrics(test_dataloader)\n",
        "\n",
        "print(f\"test mse loss {math.sqrt(mean_squared_error(y_arr,pred_arr))}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(30,10))\n",
        "plt.title('Ground Truth sensor measurement vs Forecast', fontsize=30)\n",
        "plt.plot([i for i in range(len(y_arr))], y_arr, \"-b\", label=\"Ground Truth\")\n",
        "# plt.plot([i for i in range(len(pred_arr))], pred_arr, \"-r\", label=\"Forecast\")\n",
        "plt.legend(loc=\"upper left\",fontsize=20)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SUf7mtHpaXfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PJBU2Azph3V"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(30,10))\n",
        "plt.title('Ground Truth sensor measurement vs Forecast', fontsize=30)\n",
        "# plt.plot([i for i in range(len(y_arr))], y_arr, \"-b\", label=\"Ground Truth\")\n",
        "plt.plot([i for i in range(len(pred_arr))], pred_arr, \"-r\", label=\"Forecast\")\n",
        "plt.legend(loc=\"upper left\",fontsize=20)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "frL5UcQr5QvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "function ClickConnect(){\n",
        "    console.log(\"Clicked on connect button\"); \n",
        "    document.querySelector(\"colab-connect-button\").click()\n",
        "}\n",
        "setInterval(ClickConnect,60000)"
      ],
      "metadata": {
        "id": "2BNVbj3A0WMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxt14Tp-jyLB"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100",
      "private_outputs": true,
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}